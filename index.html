<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Avaloka Meditation</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />

<!-- TensorFlow -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>

<!-- COCO-SSD -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<!-- MediaPipe Pose -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>

<style>
body {
  margin: 0;
  background: #000;
  color: #fff;
  font-family: system-ui;
  text-align: center;
}
#container {
  position: relative;
}
video, canvas {
  width: 100%;
}
#status {
  position: fixed;
  bottom: 12px;
  width: 100%;
  font-size: 14px;
  opacity: 0.7;
}
</style>
</head>

<body>

<div id="container">
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>
</div>
<div id="status">Waiting for presence…</div>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const statusEl = document.getElementById("status");

let cocoModel, poseModel;

/* ===== STATE ===== */
let presenceStart = null;
let sessionStarted = false;
let lastHead = null;

/* ===== CONFIG ===== */
const WAIT_SECONDS = 12;

/* ===== VOICE ===== */
function speak(text) {
  const u = new SpeechSynthesisUtterance(text);
  u.rate = 0.85;
  u.pitch = 1;
  speechSynthesis.cancel();
  speechSynthesis.speak(u);
}

/* ===== CAMERA ===== */
async function initCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "environment" }
  });
  video.srcObject = stream;
  return new Promise(r => video.onloadedmetadata = r);
}

/* ===== LOAD MODELS ===== */
async function loadModels() {
  cocoModel = await cocoSsd.load();

  poseModel = new Pose({
    locateFile: f =>
      `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${f}`
  });

  poseModel.setOptions({
    modelComplexity: 1,
    smoothLandmarks: true,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
  });

  poseModel.onResults(onPose);
}

/* ===== SKELETON CONNECTIONS ===== */
const connections = [
  [11,13],[13,15],[12,14],[14,16],
  [11,12],[23,24],
  [11,23],[12,24],
  [23,25],[25,27],[24,26],[26,28]
];

/* ===== DRAW SKELETON ===== */
function drawSkeleton(lm) {
  ctx.strokeStyle = "rgba(0,255,200,0.6)";
  ctx.lineWidth = 3;
  connections.forEach(([a,b]) => {
    ctx.beginPath();
    ctx.moveTo(lm[a].x * canvas.width, lm[a].y * canvas.height);
    ctx.lineTo(lm[b].x * canvas.width, lm[b].y * canvas.height);
    ctx.stroke();
  });
}

/* ===== POSE RESULTS ===== */
function onPose(res) {
  if (!res.poseLandmarks) return;

  drawSkeleton(res.poseLandmarks);

  const head = res.poseLandmarks[0];
  if (lastHead && sessionStarted) {
    const movement =
      Math.abs(head.x - lastHead.x) +
      Math.abs(head.y - lastHead.y);

    if (movement > 0.02) {
      speak("Relax. Remain still.");
    }
  }
  lastHead = head;
}

/* ===== START MEDITATION ===== */
function startMeditation() {
  sessionStarted = true;
  statusEl.innerText = "Meditation started";

  speak("Please sit comfortably in front of the camera.");
  setTimeout(() => speak("Place your hands relaxed, palms upward."), 4000);
  setTimeout(() => speak("Keep your spine naturally straight."), 8000);
  setTimeout(() => speak("Close your eyes gently."), 12000);
  setTimeout(() => speak("Bring attention between your eyebrows."), 16000);
  setTimeout(() => speak("Slowly breathe in."), 20000);
  setTimeout(() => speak("Slowly breathe out."), 24000);
  setTimeout(() => speak("You are not the body."), 28000);
  setTimeout(() => speak("You are not the mind."), 32000);
  setTimeout(() => speak("You are pure consciousness."), 36000);
  setTimeout(() => {
    statusEl.innerText = "Silent meditation (2 minutes)";
  }, 42000);
}

/* ===== MAIN LOOP ===== */
async function detect() {
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  const preds = await cocoModel.detect(video);
  const person = preds.find(p => p.class === "person" && p.score > 0.4);

  if (person) {
    const [x,y,w,h] = person.bbox;
    ctx.strokeStyle = "#fff";
    ctx.lineWidth = 2;
    ctx.strokeRect(x,y,w,h);

    if (!presenceStart) {
      presenceStart = Date.now();
    }

    const seconds =
      Math.floor((Date.now() - presenceStart) / 1000);

    if (!sessionStarted) {
      statusEl.innerText =
        `Presence detected · starting in ${Math.max(WAIT_SECONDS - seconds,0)}s`;
    }

    if (seconds >= WAIT_SECONDS && !sessionStarted) {
      startMeditation();
    }

  } else {
    presenceStart = null;
    if (!sessionStarted) {
      statusEl.innerText = "Waiting for presence…";
    }
  }

  await poseModel.send({ image: video });
  requestAnimationFrame(detect);
}

/* ===== INIT ===== */
(async () => {
  await initCamera();
  statusEl.innerText = "Camera ready…";
  await loadModels();
  statusEl.innerText = "Waiting for presence…";
  detect();
})();
</script>

</body>
</html>
