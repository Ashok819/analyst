<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Avaloka Yoga – AI Awareness</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- TensorFlow -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>

  <!-- COCO SSD -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <!-- MediaPipe Pose -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <style>
    body {
      margin: 0;
      background: #0f2027;
      font-family: system-ui;
      color: white;
      text-align: center;
    }

    h2 {
      margin: 10px 0;
    }

    #container {
      position: relative;
      width: 100%;
      max-width: 480px;
      margin: auto;
    }

    video, canvas {
      width: 100%;
      border-radius: 12px;
    }

    #status {
      margin: 10px;
      font-size: 14px;
      opacity: 0.8;
    }
  </style>
</head>

<body>

<h2>Avaloka Yoga – Awareness Mode</h2>
<div id="status">Loading models…</div>

<div id="container">
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>
</div>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const statusEl = document.getElementById("status");

let cocoModel;
let pose;

async function initCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "user" }
  });
  video.srcObject = stream;

  return new Promise(resolve => {
    video.onloadedmetadata = () => {
      video.play();
      resolve();
    };
  });
}

async function loadModels() {
  cocoModel = await cocoSsd.load();
  statusEl.innerText = "COCO-SSD loaded";

  pose = new Pose({
    locateFile: file =>
      `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
  });

  pose.setOptions({
    modelComplexity: 1,
    smoothLandmarks: true,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
  });

  pose.onResults(onPoseResults);
}

async function detect() {
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;

  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  /* COCO-SSD → Bounding Box */
  const predictions = await cocoModel.detect(video);
  predictions.forEach(p => {
    if (p.class === "person") {
      const [x, y, w, h] = p.bbox;
      ctx.strokeStyle = "#00ffcc";
      ctx.lineWidth = 2;
      ctx.strokeRect(x, y, w, h);
      ctx.fillText("Presence", x, y - 5);
    }
  });

  /* MediaPipe Pose */
  await pose.send({ image: video });

  requestAnimationFrame(detect);
}

function onPoseResults(results) {
  if (!results.poseLandmarks) return;

  ctx.fillStyle = "#ffcc00";

  results.poseLandmarks.forEach(lm => {
    ctx.beginPath();
    ctx.arc(lm.x * canvas.width, lm.y * canvas.height, 4, 0, 2 * Math.PI);
    ctx.fill();
  });

  statusEl.innerText = "Observing body & presence…";
}

async function start() {
  await initCamera();
  await loadModels();
  detect();
}

start();
</script>

</body>
</html>
