<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Avaloka Meditation</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>

<style>
body {
  margin: 0;
  background: #000;
  color: #fff;
  font-family: system-ui;
  text-align: center;
}
video, canvas {
  width: 100%;
}
#status {
  position: fixed;
  bottom: 10px;
  width: 100%;
  opacity: 0.6;
  font-size: 14px;
}
</style>
</head>

<body>

<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<div id="status">Waitingâ€¦</div>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const statusEl = document.getElementById("status");

let cocoModel, faceModel;
let sessionStarted = false;
let silenceStart = null;
let lastHeadY = null;

function speak(text) {
  const u = new SpeechSynthesisUtterance(text);
  u.rate = 0.85;
  u.pitch = 1;
  speechSynthesis.cancel();
  speechSynthesis.speak(u);
}

/* Camera (Back if available) */
navigator.mediaDevices.getUserMedia({
  video: { facingMode: "environment" }
}).then(stream => video.srcObject = stream);

/* Load Models */
(async () => {
  cocoModel = await cocoSsd.load();

  faceModel = new FaceMesh({
    locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`
  });

  faceModel.setOptions({
    maxNumFaces: 1,
    refineLandmarks: true
  });

  faceModel.onResults(onFace);
})();

/* Face Logic */
function onFace(res) {
  if (!res.multiFaceLandmarks) return;

  const face = res.multiFaceLandmarks[0];
  const leftEye = face[159];
  const rightEye = face[386];

  const eyesOpen = Math.abs(leftEye.y - rightEye.y) < 0.01;

  if (eyesOpen) {
    speak("Gently close your eyes");
  }
}

/* Main Loop */
async function detect() {
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;

  ctx.drawImage(video,0,0,canvas.width,canvas.height);

  const preds = await cocoModel.detect(video);
  const person = preds.find(p => p.class === "person");

  if (person && !sessionStarted) {
    sessionStarted = true;
    speak("Please sit comfortably in front of the camera");
    setTimeout(() => speak("Relax your body"), 3000);
    setTimeout(() => speak("Close your eyes gently"), 6000);
    setTimeout(() => speak("Breathe in"), 9000);
    setTimeout(() => speak("Breathe out"), 12000);
    silenceStart = Date.now();
  }

  if (sessionStarted) {
    if (Date.now() - silenceStart > 120000) {
      statusEl.innerText = "Silent meditation";
    }
  }

  await faceModel.send({image: video});
  requestAnimationFrame(detect);
}

detect();
</script>

</body>
</html>
