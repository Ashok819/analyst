<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Avaloka Yoga – Back Camera Pose Guide</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- TensorFlow -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>

<!-- COCO SSD -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<!-- MediaPipe Pose -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

<style>
body {
  margin: 0;
  background: #0f2027;
  font-family: system-ui;
  color: white;
  text-align: center;
}

h2 {
  margin: 10px 0;
}

#container {
  position: relative;
  max-width: 480px;
  margin: auto;
}

video, canvas {
  width: 100%;
  border-radius: 12px;
}

#status {
  font-size: 14px;
  opacity: 0.8;
  margin: 6px;
}
</style>
</head>

<body>

<h2>Avaloka Yoga – Pose Awareness</h2>
<div id="status">Loading models…</div>

<div id="container">
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>
</div>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const statusEl = document.getElementById("status");

let cocoModel, poseModel;

/* Skeleton connections */
const connections = [
  [11,13],[13,15],
  [12,14],[14,16],
  [11,12],
  [23,24],
  [11,23],[12,24],
  [23,25],[25,27],
  [24,26],[26,28]
];

/* Camera – BACK CAMERA */
async function initCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: {
      facingMode: { exact: "environment" }
    }
  });
  video.srcObject = stream;

  return new Promise(resolve => {
    video.onloadedmetadata = () => {
      video.play();
      resolve();
    };
  });
}

/* Load Models */
async function loadModels() {
  cocoModel = await cocoSsd.load();

  poseModel = new Pose({
    locateFile: f =>
      `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${f}`
  });

  poseModel.setOptions({
    modelComplexity: 1,
    smoothLandmarks: true,
    minDetectionConfidence: 0.6,
    minTrackingConfidence: 0.6
  });

  poseModel.onResults(onPoseResults);
}

/* Draw Skeleton */
function drawSkeleton(landmarks) {
  ctx.strokeStyle = "#00ffcc";
  ctx.lineWidth = 3;

  connections.forEach(([a,b]) => {
    const p1 = landmarks[a];
    const p2 = landmarks[b];
    ctx.beginPath();
    ctx.moveTo(p1.x * canvas.width, p1.y * canvas.height);
    ctx.lineTo(p2.x * canvas.width, p2.y * canvas.height);
    ctx.stroke();
  });
}

/* Pose Results */
function onPoseResults(results) {
  if (!results.poseLandmarks) return;

  drawSkeleton(results.poseLandmarks);

  ctx.fillStyle = "#ffcc00";
  results.poseLandmarks.forEach(p => {
    ctx.beginPath();
    ctx.arc(p.x * canvas.width, p.y * canvas.height, 4, 0, Math.PI*2);
    ctx.fill();
  });

  statusEl.innerText = "Align body with skeleton · remain still";
}

/* Detection Loop */
async function detect() {
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;

  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  // COCO-SSD → bounding box
  const preds = await cocoModel.detect(video);
  preds.forEach(p => {
    if (p.class === "person") {
      const [x,y,w,h] = p.bbox;
      ctx.strokeStyle = "#ffffff";
      ctx.lineWidth = 2;
      ctx.strokeRect(x,y,w,h);
      ctx.fillText("Presence", x, y - 5);
    }
  });

  // MediaPipe Pose
  await poseModel.send({ image: video });

  requestAnimationFrame(detect);
}

/* Start */
async function start() {
  await initCamera();
  await loadModels();
  detect();
}

start();
</script>

</body>
</html>
