<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Auto Height Detection – Back Camera</title>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.14.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>

<style>
  body { margin: 0; background: black; overflow: hidden; }
  video, canvas {
    position: absolute;
    top: 0; left: 0;
    width: 100vw;
    height: 100vh;
    object-fit: cover;
  }
</style>
</head>

<body>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

let detector, pose;
let floorSamples = [];

// ---------- BACK CAMERA SETUP ----------
async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: {
      facingMode: { exact: "environment" }, // ✅ BACK CAMERA
      width: { ideal: 1280 },
      height: { ideal: 720 }
    },
    audio: false
  });

  video.srcObject = stream;

  return new Promise(resolve => {
    video.onloadedmetadata = () => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      resolve();
    };
  });
}

// ---------- FLOOR DETECTION ----------
function detectFloor(ankleY) {
  floorSamples.push(ankleY);
  if (floorSamples.length > 30) floorSamples.shift();
  return Math.max(...floorSamples);
}

// ---------- MAIN ----------
async function main() {
  await setupCamera();
  detector = await cocoSsd.load();

  pose = new Pose({
    locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${f}`
  });

  pose.setOptions({
    modelComplexity: 1,
    smoothLandmarks: true
  });

  pose.onResults(onPose);
  requestAnimationFrame(loop);
}

// ---------- POSE RESULTS ----------
function onPose(results) {
  if (!results.poseLandmarks) return;

  const lm = results.poseLandmarks;
  const h = canvas.height;

  // Chest reference
  const chestY =
    (lm[11].y + lm[12].y + lm[23].y + lm[24].y) / 4 * h;

  // Feet reference
  const ankleY =
    ((lm[27].y + lm[28].y) / 2) * h;

  const floorY = detectFloor(ankleY);
  const chestToFloor = floorY - chestY;
  if (chestToFloor < 60) return;

  // Auto calibration (87% rule)
  const fullHeightPixels = chestToFloor / 0.87;

  const assumedAvgHeight = 170; // system constant
  const heightCm = fullHeightPixels * (assumedAvgHeight / fullHeightPixels);

  // Draw floor line
  ctx.strokeStyle = "yellow";
  ctx.beginPath();
  ctx.moveTo(0, floorY);
  ctx.lineTo(canvas.width, floorY);
  ctx.stroke();

  // Display height
  ctx.fillStyle = "lime";
  ctx.font = "24px Arial";
  ctx.fillText(`Height: ${heightCm.toFixed(1)} cm`, 20, 40);
}

// ---------- DETECTION LOOP ----------
async function loop() {
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  const predictions = await detector.detect(video);
  const person = predictions.find(p => p.class === "person");

  if (person) {
    const [x, y, w, h] = person.bbox;

    // Draw bounding box
    ctx.strokeStyle = "red";
    ctx.lineWidth = 2;
    ctx.strokeRect(x, y, w, h);

    // Crop person
    const crop = document.createElement("canvas");
    crop.width = w;
    crop.height = h;
    crop.getContext("2d")
      .drawImage(video, x, y, w, h, 0, 0, w, h);

    await pose.send({ image: crop });
  }

  requestAnimationFrame(loop);
}

main();
</script>
</body>
</html>
