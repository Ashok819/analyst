<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Avaloka Meditation</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>

<style>
body {
  margin: 0;
  background: #000;
  color: #fff;
  font-family: system-ui;
  text-align: center;
}
video, canvas { width: 100%; }
#status {
  position: fixed;
  bottom: 80px;
  width: 100%;
  opacity: 0.7;
}
#startBtn {
  position: fixed;
  bottom: 20px;
  left: 50%;
  transform: translateX(-50%);
  padding: 14px 30px;
  font-size: 16px;
  border-radius: 30px;
  border: none;
}
</style>
</head>

<body>

<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<div id="status">Tap START to enable voice</div>
<button id="startBtn">START</button>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const statusEl = document.getElementById("status");
const startBtn = document.getElementById("startBtn");

let cocoModel, poseModel;
let voicesReady = false;
let presenceStart = null;
let sessionStarted = false;
let lastHead = null;

const WAIT_SECONDS = 12;

/* ---------- VOICE INITIALIZATION (CRITICAL) ---------- */
function initVoice() {
  return new Promise(resolve => {
    let voices = speechSynthesis.getVoices();
    if (voices.length) {
      voicesReady = true;
      resolve();
    } else {
      speechSynthesis.onvoiceschanged = () => {
        voicesReady = true;
        resolve();
      };
    }
  });
}

function speak(text) {
  if (!voicesReady) return;
  const u = new SpeechSynthesisUtterance(text);
  u.rate = 0.85;
  u.pitch = 1;
  speechSynthesis.cancel();
  speechSynthesis.speak(u);
}

/* ---------- START BUTTON (UNLOCKS AUDIO) ---------- */
startBtn.onclick = async () => {
  startBtn.style.display = "none";
  statusEl.innerText = "Initializingâ€¦";

  await initVoice();

  // ðŸ”‘ MUST speak immediately on click (iOS rule)
  speak("Voice guidance enabled");

  await initCamera();
  await loadModels();

  statusEl.innerText = "Waiting for presenceâ€¦";
  detect();
};

/* ---------- CAMERA ---------- */
async function initCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "environment" }
  });
  video.srcObject = stream;
  return new Promise(r => video.onloadedmetadata = r);
}

/* ---------- MODELS ---------- */
async function loadModels() {
  cocoModel = await cocoSsd.load();

  poseModel = new Pose({
    locateFile: f =>
      `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${f}`
  });

  poseModel.setOptions({
    modelComplexity: 1,
    smoothLandmarks: true,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
  });

  poseModel.onResults(onPose);
}

/* ---------- SKELETON ---------- */
const connections = [
  [11,13],[13,15],[12,14],[14,16],
  [11,12],[23,24],
  [11,23],[12,24]
];

function onPose(res) {
  if (!res.poseLandmarks) return;

  ctx.strokeStyle = "rgba(0,255,200,0.6)";
  ctx.lineWidth = 3;

  connections.forEach(([a,b]) => {
    const p1 = res.poseLandmarks[a];
    const p2 = res.poseLandmarks[b];
    ctx.beginPath();
    ctx.moveTo(p1.x*canvas.width, p1.y*canvas.height);
    ctx.lineTo(p2.x*canvas.width, p2.y*canvas.height);
    ctx.stroke();
  });

  const head = res.poseLandmarks[0];
  if (lastHead && sessionStarted) {
    const move =
      Math.abs(head.x-lastHead.x)+Math.abs(head.y-lastHead.y);
    if (move > 0.02) speak("Relax. Remain still.");
  }
  lastHead = head;
}

/* ---------- START MEDITATION ---------- */
function startMeditation() {
  sessionStarted = true;
  statusEl.innerText = "Meditation started";

  speak("Please sit comfortably in front of the camera.");
  setTimeout(()=>speak("Relax your hands, palms upward."),4000);
  setTimeout(()=>speak("Keep your spine naturally straight."),8000);
  setTimeout(()=>speak("Close your eyes gently."),12000);
  setTimeout(()=>speak("Slowly breathe in."),16000);
  setTimeout(()=>speak("Slowly breathe out."),20000);
  setTimeout(()=>speak("You are pure consciousness."),24000);
}

/* ---------- LOOP ---------- */
async function detect() {
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  ctx.drawImage(video,0,0,canvas.width,canvas.height);

  const preds = await cocoModel.detect(video);
  const person = preds.find(p => p.class==="person" && p.score>0.4);

  if (person) {
    if (!presenceStart) presenceStart = Date.now();
    const t = (Date.now()-presenceStart)/1000;

    statusEl.innerText =
      `Presence detected Â· starting in ${Math.max(12-Math.floor(t),0)}s`;

    if (t>=WAIT_SECONDS && !sessionStarted) startMeditation();
  } else {
    presenceStart = null;
    if (!sessionStarted) statusEl.innerText = "Waiting for presenceâ€¦";
  }

  await poseModel.send({image: video});
  requestAnimationFrame(detect);
}
</script>

</body>
</html>
